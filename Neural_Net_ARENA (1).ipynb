{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "97da4226",
      "metadata": {
        "id": "97da4226"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Need this for some of the helper functions\n",
        "\n",
        "import torch as t\n",
        "\n",
        "# Some nice preliminary functions for testing.\n",
        "\n",
        "def assert_with_expect(expected, actual):\n",
        "    assert expected == actual, f\"Expected: {expected} Actual: {actual}\"\n",
        "\n",
        "\n",
        "def assert_list_of_floats_within_epsilon(\n",
        "    expected: list[float],\n",
        "    actual: list[float],\n",
        "    eps=0.0001,\n",
        "):\n",
        "    if len(expected) != len(actual):\n",
        "        raise AssertionError(f\"Expected: {expected} Actual: {actual}\")\n",
        "    is_within_eps = True\n",
        "    for e, a in zip(expected, actual):\n",
        "        is_within_eps = is_within_eps and abs(e - a) < eps\n",
        "    if not is_within_eps:\n",
        "        raise AssertionError(f\"Expected: {expected} Actual: {actual}\")\n",
        "\n",
        "\n",
        "def assert_tensors_within_epsilon(\n",
        "    expected: t.Tensor,\n",
        "    actual: t.Tensor,\n",
        "    eps=0.001,\n",
        "):\n",
        "    if expected.shape != actual.shape:\n",
        "        raise AssertionError(f\"Shapes of tensors do not match! Expected: {expected.shape} Acutal: {actual.shape}\")\n",
        "    differences_within_epsilon = abs(expected - actual) < eps\n",
        "    if not differences_within_epsilon.all():\n",
        "        raise AssertionError(f\"Values of tensors do not match! Expected: {expected} Actual: {actual}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "53288c88",
      "metadata": {
        "id": "53288c88"
      },
      "outputs": [],
      "source": [
        "\n",
        "# We're going to begin by defining neural networks in a way that emphasizes\n",
        "# each individual neuron. This is very inefficient and impractical for any real\n",
        "# neural network (at least in Python). Also by thinking at the individual neuron\n",
        "# level, this obscures a lot of larger structures in a neural net that can\n",
        "# actually make it more difficult to understand what's going on at a high-level.\n",
        "#\n",
        "# Nonetheless, it's a reasonable starting point for understanding why we call a\n",
        "# neural net \"neural.\" We'll redo our neural net using matrices later in this\n",
        "# section to demonstrate how they're actually written \"in the wild.\"\n",
        "#\n",
        "# Let's begin by defining one of the simplest non-linear activation functions\n",
        "# out there. We'll need this as the last step of computation when defining what\n",
        "# a single neuron does.\n",
        "\n",
        "def relu(x: float) -> float:\n",
        "    \"\"\"\n",
        "    ReLU (rectified linear unit), one of the simplest non-linear activation\n",
        "    functions out there.\n",
        "    \"\"\"\n",
        "    # TODO: Fill this in!\n",
        "    if x >= 0:\n",
        "      return x\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "assert relu(5.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "5a55b86d",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "5a55b86d"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "# Now let's define a single neuron. If you want a reminder of how a single\n",
        "# neuron is structured, look at\n",
        "# https://github.com/changlinli/intro-to-technical-ai-safety-slides/blob/master/neural_nets/slides.md#a-single-neuron-also-called-node\n",
        "# (note that the diagram is a bit misleading w.r.t. bias, bias isn't always +1,\n",
        "# it can be + some other constant!).\n",
        "#\n",
        "# For now don't worry about using tensors to carry this out, normal Python\n",
        "# iteration is perfectly fine.\n",
        "\n",
        "@dataclass\n",
        "class Neuron:\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    weights: list[float]\n",
        "    bias: float\n",
        "\n",
        "    def compute_output(self, inputs: list[float]) -> float:\n",
        "        \"\"\"\n",
        "        Compute what the output of a single neuron should look like.\n",
        "        \"\"\"\n",
        "        assert len(inputs) == len(self.weights)\n",
        "        # TODO: Fill this in!\n",
        "        summation = sum([i*j for i, j in zip(self.weights, inputs)])\n",
        "        output = summation + self.bias\n",
        "        output = relu(output)\n",
        "        return output\n",
        "\n",
        "test_neuron = Neuron(weights=[1, 2], bias=0.5)\n",
        "assert_with_expect(actual=test_neuron.compute_output([2, 3]), expected=8.5)\n",
        "assert_with_expect(actual=test_neuron.compute_output([2, -2]), expected=0)\n",
        "new_neuron = Neuron(weights=[0.5, -0.1], bias = 1.3)\n",
        "assert_with_expect(actual=new_neuron.compute_output([1, 2]), expected=1.6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "2da4b01f",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "2da4b01f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Now let's define a forward pass for a single layer of neurons. Note that every\n",
        "# neuron must have the same number of inputs (as determined by the number of\n",
        "# weights) and it must match the number of inputs coming into the layer.\n",
        "\n",
        "def forward_pass_single_layer(input: list[float], layer: list[Neuron]) -> list[float]:\n",
        "    for neuron in layer:\n",
        "        assert len(neuron.weights) == len(input)\n",
        "    forwardpass = []\n",
        "    for i in layer:\n",
        "      forwardpass.append(i.compute_output(input))\n",
        "\n",
        "    return forwardpass\n",
        "\n",
        "test_layer = [\n",
        "    Neuron(weights=[0.1, 0.2], bias=0.3),\n",
        "    Neuron(weights=[-0.15, 0.1], bias=-0.1),\n",
        "    Neuron(weights=[0.2, 0.1], bias=0.1),\n",
        "]\n",
        "assert_list_of_floats_within_epsilon(\n",
        "    actual=forward_pass_single_layer(input=[5.5, 1.2], layer=test_layer),\n",
        "    expected=[1.09, 0.0, 1.32],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "f4158626",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "f4158626"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Now let's take `forward_pass_single_layer` and use it to perform a single\n",
        "# forward pass over an entire network with multiple layers.\n",
        "\n",
        "def forward_pass_network(initial_inputs: list[float], layers: list[list[Neuron]]) -> list[float]:\n",
        "    last_output = initial_inputs\n",
        "    for layer in layers:\n",
        "        last_output = forward_pass_single_layer(last_output, layer)\n",
        "    return last_output\n",
        "\n",
        "\n",
        "# The following is an example of a neural net that takes in two inputs and has\n",
        "# two outputs, and has three layers: 3 neurons, 2 neurons, and 2 neurons\n",
        "# Notice that:\n",
        "#   1. Because we take in two inputs, the first layer of neurons all have two weights\n",
        "#   2. Because there are three neurons that feed into the second layer, all the neurons of the second layer have three\n",
        "#      weights\n",
        "#   3. Because there are two neurons in the second layer, all the neurons of the third layer have two weights\n",
        "#   4. We have three inputs and two outputs because the first layer has three neurons and the last layer has two neurons\n",
        "demo_network: list[list[Neuron]] = \\\n",
        "    [\n",
        "        [\n",
        "            Neuron(weights=[0.1, 0.2], bias=0.3),\n",
        "            Neuron(weights=[-0.15, 0.1], bias=-0.1),\n",
        "            Neuron(weights=[0.2, 0.1], bias=0.1),\n",
        "        ],\n",
        "        [\n",
        "            Neuron(weights=[0.1, 0.2, 0.3], bias=0.3),\n",
        "            Neuron(weights=[-0.15, 0.1, 0.9], bias=-0.1),\n",
        "        ],\n",
        "        [\n",
        "            Neuron(weights=[0.1, 0.2], bias=0.3),\n",
        "            Neuron(weights=[-0.15, 0.1], bias=-0.1),\n",
        "        ],\n",
        "    ]\n",
        "\n",
        "\n",
        "assert_list_of_floats_within_epsilon(\n",
        "    expected=[0.342, 0.0],\n",
        "    actual=forward_pass_network([0.0, 1.0], demo_network),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "88f73833",
      "metadata": {
        "id": "88f73833"
      },
      "outputs": [],
      "source": [
        "\n",
        "# We could do backpropagation manually by writing out the chain rule by hand to\n",
        "# calculate each derivative. This is extremely tedious and no one does this. It\n",
        "# makes it extremely difficult to experiment with different neural nets because\n",
        "# we have to manually rederive all our derivatives each time.\n",
        "#\n",
        "# Instead ML practitioners always use some library that provides\n",
        "# autodifferentiation (also sometimes called autograd). In our case, that will\n",
        "# be PyTorch. Hence in the interests of time we'll skip writing out\n",
        "# backpropagation for our network here.\n",
        "#\n",
        "# You'll dive more into the internals of how backpropagation works when we\n",
        "# reimplement PyTorch's autodifferentiation feature.\n",
        "\n",
        "def backpropagation(network: list[list[Neuron]]):\n",
        "    # Don't worry about implementing this\n",
        "    raise NotImplementedError(\"This is too tedious to implement.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "159be55e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "159be55e",
        "outputId": "8f3aba8b-3c2c-4039-85fc-f67a579d7140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/dist-packages (0.2.31)\n",
            "Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (2.13.3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79aeec168370>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "\n",
        "import torch as t\n",
        "!pip install jaxtyping\n",
        "from jaxtyping import Float\n",
        "\n",
        "# Just to make sure our results are reproducible\n",
        "t.manual_seed(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "bfe52f64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfe52f64",
        "outputId": "d0b131c5-4698-4707-af63-58f8de42d5da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad=tensor([11.])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Here's an example of using PyTorch to automatically calculate a derivative for\n",
        "# you. When we are manually creating tensors, we have to explicitly tell PyTorch\n",
        "# to remember we want to calculate the gradient for this tensor, so we should\n",
        "# pass in requires_grad=True. As we use PyTorch more and more, we'll see a lot\n",
        "# of library calls that will automatically take care of this for us.\n",
        "#\n",
        "# All of PyTorch's functions that work on tensors keep track of which operations\n",
        "# have performed on which tensors in what PyTorch calls a \"computational graph.\"\n",
        "# It is this computational graph that allows PyTorch to automatically calculate\n",
        "# derivatives for us.\n",
        "x = t.tensor([5.0], requires_grad=True)\n",
        "\n",
        "# Derivative here is 2x + 1, so that should be a derivative of 11 for x = 5\n",
        "y = x ** 2 + x\n",
        "\n",
        "# PyTorch's auto-differentiation facilities are based entirely around mutability\n",
        "# Make sure that you call `.backward()` before you look at the gradients!\n",
        "# Otherwise the gradients will not be set.\n",
        "#\n",
        "# Note that you call the `.backward()` method on your final derived value to get\n",
        "# the gradient/derivative of one of your input variables. That is, in order to\n",
        "# get the value of dy/dx for any y and x, you must call `.backward()` on `y` to\n",
        "# first calculate all the derivatives through the computational graph and then\n",
        "# `.grad` on `x`.\n",
        "y.backward()\n",
        "\n",
        "# x.grad is the numeral calculation of dy/dx at x = 5\n",
        "#\n",
        "# We see that the derivative is indeed 11 as we calculated by hand.\n",
        "print(f\"{x.grad=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "6e4477ed",
      "metadata": {
        "id": "6e4477ed"
      },
      "outputs": [],
      "source": [
        "\n",
        "a = t.tensor([5.0], requires_grad=True)\n",
        "\n",
        "b = t.tensor([3.0], requires_grad=True)\n",
        "\n",
        "c = a ** 2 + b ** 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "e095f3f3",
      "metadata": {
        "id": "e095f3f3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Let's move on to a multivariate case.  Use PyTorch to calculate what dc/da is\n",
        "# and what dc/db are.\n",
        "\n",
        "# TODO: Fill in the Nones!\n",
        "# Remember to first populate the gradients before calling .grad!\n",
        "c.backward()\n",
        "\n",
        "dc_da = a.grad\n",
        "\n",
        "assert_with_expect(expected=t.tensor(10.0), actual=dc_da)\n",
        "\n",
        "dc_db = b.grad\n",
        "\n",
        "assert_with_expect(expected=t.tensor(6.0), actual=dc_db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "fbc43c27",
      "metadata": {
        "id": "fbc43c27"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Like almost everything else in PyTorch, autodifferentiation works with\n",
        "# multidimensional tensors as well, not just scalar values! Here's a way we\n",
        "# could calculate a and b \"at once\" in a single tensor.\n",
        "\n",
        "a_and_b = t.tensor([5.0, 3.0], requires_grad=True)\n",
        "\n",
        "c = (a_and_b ** 2).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "58ad8f76",
      "metadata": {
        "id": "58ad8f76"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Use PyTorch to calculate again what dc/da and what dc/db are\n",
        "\n",
        "# TODO: Fill in the Nones!\n",
        "# Remember to first populate the gradients before calling .grad!\n",
        "c.backward()\n",
        "\n",
        "dc_da = a_and_b.grad[0]\n",
        "\n",
        "dc_db = a_and_b.grad[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "bcab2fd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcab2fd3",
        "outputId": "e3625afc-8c0f-4c0f-c9c2-0f21b50ace50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "some_input.grad=tensor([10.])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# If you construct different computational graphs that involve the same set of\n",
        "# input tensors and `.backward()` is called each time (so that each input tensor\n",
        "# has had the result of `.backward()` flow through multiple times), gradients\n",
        "# will \"accumulate.\" For our purposes this is usually undesirable.\n",
        "#\n",
        "# Let's go over what that means and how to avoid this.  First let's create\n",
        "# tensors as usual.\n",
        "\n",
        "some_input = t.tensor([1.0], requires_grad=True)\n",
        "\n",
        "some_output = 10 * some_input\n",
        "\n",
        "some_output.backward()\n",
        "\n",
        "# Normally because this is just y = 10 * x, we would expect the x's gradient to\n",
        "# be 10 at this point. And indeed it is.\n",
        "\n",
        "print(f\"{some_input.grad=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "d0b58328",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0b58328",
        "outputId": "893c4683-020a-4b2f-8731-2eca995f569e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch was smart enough to blow up and prevent us from going backward again with the following message:\n",
            "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# PyTorch is smart enough to warn us if we try to use backward again\n",
        "\n",
        "try:\n",
        "    some_output.backward()\n",
        "except RuntimeError as e:\n",
        "    print(f\"PyTorch was smart enough to blow up and prevent us from going backward again with the following message:\\n{str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "ee82d8b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee82d8b1",
        "outputId": "ffc9c5b6-b42d-4541-906e-288b818edbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "some_input.grad=tensor([15.])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# But PyTorch doesn't warn us if we create a new output that reuses `some_input`\n",
        "# and instead will just keep adding more gradients to the pre-existing gradient.\n",
        "# This is known as \"accumulating gradients,\" and there are reasons you might\n",
        "# want to do this, but for our purposes, this is undesirable, as it will give us\n",
        "# the wrong derivatives/gradients.\n",
        "\n",
        "another_output = 5 * some_input\n",
        "\n",
        "another_output.backward()\n",
        "\n",
        "# Note that we've added two derivatives together, 10 + 5, which is not the\n",
        "# correct derivative for y = 10 * x or y = 5 * x!\n",
        "assert some_input.grad == 15\n",
        "\n",
        "print(f\"{some_input.grad=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "08793b47",
      "metadata": {
        "id": "08793b47"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Because PyTorch will either throw an error on a given backwards call, or it'll\n",
        "# accumulate gradients when you potentially don't want that to happen, we\n",
        "# generally will want to reset gradients between calls to backward(). The\n",
        "# easiest way to do this is to set `.grad = None`. We'll see later how to do\n",
        "# this in a less manual fashion.\n",
        "\n",
        "some_input.grad = None\n",
        "\n",
        "yet_another_output = 5 * some_input\n",
        "\n",
        "yet_another_output.backward()\n",
        "\n",
        "# This time we get the correct gradient!\n",
        "assert some_input.grad == 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "f96ea45a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f96ea45a",
        "outputId": "3951f6de-1bc5-47eb-d998-4bac8f99f924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yep we still get the following error message:\n",
            "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Note that even after resetting a gradient, we still can't call backward again\n",
        "# on the same output. This has to do with the details of how PyTorch\n",
        "# automatically calculates derivatives. The exact details of why this is the\n",
        "# case are irrelevant at the moment (although they may become more apparent when\n",
        "# we implement backpropagation ourselves), but feel free to ask if you're\n",
        "# curious.\n",
        "\n",
        "some_input.grad = None\n",
        "\n",
        "try:\n",
        "    yet_another_output.backward()\n",
        "except RuntimeError as e:\n",
        "    print(f\"Yep we still get the following error message:\\n{str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "ace061c2",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ace061c2",
        "outputId": "e79f24b9-e668-4c9c-fd1e-655fc757d020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "result=array([[0.9161693 , 0.96571314],\n",
            "       [0.62499666, 1.2300433 ],\n",
            "       [0.4278946 , 0.8236524 ],\n",
            "       ...,\n",
            "       [0.5376427 , 1.2865753 ],\n",
            "       [1.2533709 , 1.2951387 ],\n",
            "       [0.7369081 , 1.3586906 ]], dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Let's drive home the notion that PyTorch's autodifferentiation handles\n",
        "# multidimensional tensors just fine, since this will often show up. We'll have\n",
        "# PyTorch calculate 2000 derivatives at once (i.e. calculate a single gradient\n",
        "# consisting of 2000 components)!\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "one_thousand_random_points: Float[t.Tensor, \"1000 2\"] = t.rand(1000, 2, requires_grad=True)\n",
        "\n",
        "assert one_thousand_random_points.requires_grad\n",
        "\n",
        "# Using `one_thousand_random_points`, call $f(x_i, y_i) = \\sum_{0 <= i < 1000} x_i^2 + y_i^2$, (notice that\n",
        "# the thousand points are all (x, y) pairs because the second dimension is 2).\n",
        "\n",
        "def gradient_of_x_squared_plus_y_squared_plus_5_thousand_times() -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Usually a Tensor will calculate its gradient as another Tensor, but here\n",
        "    we'll return a NumPy array.\n",
        "\n",
        "    We will calculate this for the function $f(x_i, y_i) = \\sum_{0 <= i < 1000} x_i^2 + y_i^2$\n",
        "\n",
        "    You should use `one_thousand_random_points` to generate the 1000 points\n",
        "    and then should ultimately return a 1000x2 NumPy array, representing a 1000x2 gradient.\n",
        "\n",
        "    Note to turn a PyTorch tensor into a NumPy array, call the .detach().numpy() method\n",
        "    on a tensor.\n",
        "    \"\"\"\n",
        "    points = one_thousand_random_points\n",
        "    x, y = points[:,0], points[:, 1]\n",
        "    out = sum(x**2 + y**2)\n",
        "    out.backward()\n",
        "    return points.grad.detach().numpy()\n",
        "\n",
        "\n",
        "\n",
        "result = gradient_of_x_squared_plus_y_squared_plus_5_thousand_times()\n",
        "print(f\"{result=}\")\n",
        "assert_with_expect(expected=one_thousand_random_points[0][0] * 2, actual=result[0][0])\n",
        "assert_with_expect(expected=one_thousand_random_points[1][1] * 2, actual=result[1][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "d07d797d",
      "metadata": {
        "id": "d07d797d"
      },
      "outputs": [],
      "source": [
        "#!pip install einops\n",
        "import einops\n",
        "\n",
        "# Recall that a higher-level way of thinking about a neural layer net is that it\n",
        "# is a general linear function with an added constant, followed by a non-linear\n",
        "# function. Let's begin by implementing application of a linear function.\n",
        "# Remember that a function from a vector space of dimension n to a vector space\n",
        "# of dimension m can be implemented as an m x n matrix.\n",
        "#\n",
        "# There is a major benefit in implementing a neural net layer this way: an\n",
        "# entire batch of inputs can be processed simultaneously! Instead of passing in\n",
        "# a single vector of size d_input, we're going to pass in a whole block of them\n",
        "# at once, in the form of a batch x d_input tensor.\n",
        "#\n",
        "# You should be able to write in this one or two lines without any iteration.\n",
        "# You can either use einops.einsum or you can use built-in PyTorch methods.\n",
        "\n",
        "def apply_linear_function_to_input(\n",
        "    linear_function: Float[t.Tensor, \"d_output d_input\"],\n",
        "    input_to_function: Float[t.Tensor, \"batch d_input\"],\n",
        ") -> Float[t.Tensor, \"batch d_output\"]:\n",
        "    #return einops.einsum(input_to_function, linear_function, \"batch d_input, d_output d_input -> batch d_output\")\n",
        "    return input_to_function @ linear_function.T\n",
        "\n",
        "# 3x2 matrix, i.e. f: R^2 -> R^3\n",
        "test_linear_function = t.tensor(\n",
        "    [\n",
        "        [1.0, 2.0],\n",
        "        [3.0, 4.0],\n",
        "        [5.0, 6.0],\n",
        "    ]\n",
        ")\n",
        "# A batch size of 4 vectors all combined together\n",
        "test_input = t.tensor(\n",
        "    [\n",
        "        [0.5, 0.6],\n",
        "        [0.3, 0.4],\n",
        "        [-2.0, -9.0],\n",
        "        [-8.0, 1.0],\n",
        "    ]\n",
        ")\n",
        "test_output = apply_linear_function_to_input(linear_function=test_linear_function, input_to_function=test_input)\n",
        "expected_output = t.tensor(\n",
        "    [\n",
        "        [1.7, 3.9, 6.1],\n",
        "        [1.1, 2.5, 3.9],\n",
        "        [-20, -42, -64],\n",
        "        [-6, -20, -34]\n",
        "    ]\n",
        ")\n",
        "\n",
        "assert_tensors_within_epsilon(\n",
        "    expected=expected_output,\n",
        "    actual=test_output,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "9419fd36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9419fd36",
        "outputId": "13914d3e-aa42-4bb2-d319-e44577e0e5df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example_input.grad=tensor([[24.6366, 25.4809]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# And as we expect, gradients flow through automatically.\n",
        "example_input = t.rand((1, 2), requires_grad=True)\n",
        "example_result = apply_linear_function_to_input(example_input, t.rand((50, 2))).sum()\n",
        "example_result.backward()\n",
        "print(f\"{example_input.grad=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "78d9fd4a",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "78d9fd4a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Putting this together, we can create a three layer neural net consisting of\n",
        "# six tensors, instead of needing to create each neuron individually.\n",
        "\n",
        "@dataclass\n",
        "class ThreeLayerNeuralNet:\n",
        "    layer_0: Float[t.Tensor, \"d_output_0 d_input\"]\n",
        "    layer_0_bias: Float[t.Tensor, \"d_output_0\"]\n",
        "    layer_1: Float[t.Tensor, \"d_output_1 d_output_0\"]\n",
        "    layer_1_bias: Float[t.Tensor, \"d_output_1\"]\n",
        "    layer_2: Float[t.Tensor, \"d_output_2 d_output_1\"]\n",
        "    layer_2_bias: Float[t.Tensor, \"d_output_2\"]\n",
        "\n",
        "# Now that we have the class structure, let's create a way of actually\n",
        "# initializing the neural net.\n",
        "#\n",
        "# Ultimately we're going to be creating a neural net to recognize handwritten\n",
        "# digits, so it'll have an output of 10 digits.\n",
        "#\n",
        "# In our case we're going to create a very specific neural net. It's going to be\n",
        "# a series of layers going from an input of dimension 784 to 2000 to 400 and\n",
        "# finally to 10. That is:\n",
        "#\n",
        "# + d_input = 784\n",
        "# + d_output_0 = 2000\n",
        "# + d_output_1 = 400\n",
        "# + d_output_2 = 10\n",
        "#\n",
        "# 784 is because our images are of size 28x28. The intermediate dimensions of\n",
        "# 2000 and 400 in our hidden layers are chosen more or less arbitrarily. We'll\n",
        "# see some rules of thumb for sizing these layers later.\n",
        "#\n",
        "# Let's go ahead and implement that! We've provided the first\n",
        "# few lines of this, fill in the rest (making sure to call\n",
        "# ``.uniform_(-initial_bound, initial_bound`)).\n",
        "def initialize_new_three_layer_net() -> ThreeLayerNeuralNet:\n",
        "    \"\"\"\n",
        "    Initialize our\n",
        "    \"\"\"\n",
        "    # Since we have ReLU that clamps values to 0, having an initial set of\n",
        "    # weights that are all 0 can sometimes cause gradients to be stuck at 0 and\n",
        "    # never move. So we generally want to inject a little bit of randomness when\n",
        "    # initializing and move weights just a little bit away from 0.\n",
        "    #\n",
        "    # We also can't have these bounds be too big! Otherwise again ReLU may bite\n",
        "    # us and clamp us down to 0 if there's a sign change somewhere.\n",
        "    #\n",
        "    # This particular bound was chosen semi-randomly (I kind of pulled it out of\n",
        "    # a hat and verified that it worked). You'll see later a slightly more\n",
        "    # principled/standard way of choosing this bound.\n",
        "    initial_bound = 1 / 20\n",
        "    with t.no_grad():\n",
        "        neural_net = ThreeLayerNeuralNet(\n",
        "            # We're going to use usual matrix order of dimensions here That is\n",
        "            # for a matrix mxn, that means we have n-dimensional input and\n",
        "            # m-dimensional output, so likewise here (300, 784) means\n",
        "            # 784-dimensional input and 300-dimensional output\n",
        "            layer_0 = t.zeros((2000, 784), requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
        "            layer_0_bias = t.zeros(2000, requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
        "            layer_1 = t.zeros((400, 2000), requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
        "            layer_1_bias = t.zeros(400, requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
        "            layer_2 = t.zeros((10, 400), requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
        "            layer_2_bias = t.zeros(10, requires_grad=True).uniform_(-initial_bound, initial_bound),\n",
        "        )\n",
        "        return neural_net\n",
        "\n",
        "\n",
        "new_neural_net = initialize_new_three_layer_net()\n",
        "\n",
        "assert_with_expect(\n",
        "    expected=(400, 2000),\n",
        "    actual=new_neural_net.layer_1.shape,\n",
        ")\n",
        "assert_with_expect(\n",
        "    expected=(10, 400),\n",
        "    actual=new_neural_net.layer_2.shape,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "c7b8bb0f",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "c7b8bb0f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# We'll need a version of ReLU that works with tensors of arbitrary size. Let's implement that:\n",
        "\n",
        "def tensor_relu(input_tensor: t.Tensor) -> t.Tensor:\n",
        "    #return t.max(t.zeros(input_tensor.shape), input_tensor)\n",
        "    return input_tensor.clamp_min(0)\n",
        "\n",
        "test_input = t.tensor([\n",
        "    [1.0, 2.0, -3.0],\n",
        "    [4.0, -5.0, 6.0],\n",
        "])\n",
        "assert_tensors_within_epsilon(\n",
        "    expected=t.tensor([\n",
        "        [1.0, 2.0, 0.0],\n",
        "        [4.0, 0.0, 6.0],\n",
        "    ]),\n",
        "    actual=tensor_relu(test_input)\n",
        ")\n",
        "\n",
        "\n",
        "# Now let's define a version of `forward` that works with tensors. Again, our\n",
        "# input tensor is a whole batch of inputs, not just a single input!\n",
        "#\n",
        "# Our last layer will use a softmax, which is a function that normalizes a\n",
        "# vector to be between 0 and 1 and to sum to 1. This helps with stability in\n",
        "# training and lets us interpret each of the 10 components in our output as a\n",
        "# probability. You can read\n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html for\n",
        "# more details.\n",
        "\n",
        "def forward(x: Float[t.Tensor, \"batch d_input\"], neural_net: ThreeLayerNeuralNet) -> Float[t.Tensor, \"batch d_output\"]:\n",
        "    x = apply_linear_function_to_input(neural_net.layer_0, x) + neural_net.layer_0_bias\n",
        "    x = tensor_relu(x)\n",
        "    print(x.shape)\n",
        "    x = apply_linear_function_to_input(neural_net.layer_1, x) + neural_net.layer_1_bias\n",
        "    print(x.shape)\n",
        "    x = tensor_relu(x)\n",
        "    print(x.shape)\n",
        "    x = apply_linear_function_to_input(neural_net.layer_2, x) + neural_net.layer_2_bias\n",
        "    print(x.shape)\n",
        "    x = tensor_relu(x)\n",
        "    print(x.shape)\n",
        "    return x\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "c38802f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c38802f0",
        "outputId": "a97dc05c-740f-4a90-ff99-4838205c9225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 2000])\n",
            "torch.Size([10, 400])\n",
            "torch.Size([10, 400])\n",
            "torch.Size([10, 10])\n",
            "torch.Size([10, 10])\n",
            "example_output=tensor([[0.0118, 0.0000, 0.0000, 0.1383, 0.0000, 0.1108, 0.0000, 0.0000, 0.2502,\n",
            "         0.0000],\n",
            "        [0.0118, 0.0000, 0.0000, 0.1383, 0.0000, 0.1108, 0.0000, 0.0000, 0.2502,\n",
            "         0.0000],\n",
            "        [0.0118, 0.0000, 0.0000, 0.1383, 0.0000, 0.1108, 0.0000, 0.0000, 0.2502,\n",
            "         0.0000],\n",
            "        [0.0118, 0.0000, 0.0000, 0.1383, 0.0000, 0.1108, 0.0000, 0.0000, 0.2502,\n",
            "         0.0000],\n",
            "        [0.0118, 0.0000, 0.0000, 0.1383, 0.0000, 0.1108, 0.0000, 0.0000, 0.2502,\n",
            "         0.0000],\n",
            "        [0.0118, 0.0000, 0.0000, 0.1383, 0.0000, 0.1108, 0.0000, 0.0000, 0.2502,\n",
            "         0.0000],\n",
            "        [0.0118, 0.0000, 0.0000, 0.1383, 0.0000, 0.1108, 0.0000, 0.0000, 0.2502,\n",
            "         0.0000],\n",
            "        [0.0118, 0.0000, 0.0000, 0.1383, 0.0000, 0.1108, 0.0000, 0.0000, 0.2502,\n",
            "         0.0000],\n",
            "        [0.0118, 0.0000, 0.0000, 0.1383, 0.0000, 0.1108, 0.0000, 0.0000, 0.2502,\n",
            "         0.0000],\n",
            "        [0.0118, 0.0000, 0.0000, 0.1383, 0.0000, 0.1108, 0.0000, 0.0000, 0.2502,\n",
            "         0.0000]], grad_fn=<ClampMinBackward0>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "example_output = forward(neural_net=new_neural_net, x=t.ones((10, 784)))\n",
        "\n",
        "print(f\"{example_output=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "e10914a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e10914a2",
        "outputId": "7cf98534-4972-4a39-968d-296662260e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weren't able to calculate a gradient because of:\n",
            "grad can be implicitly created only for scalar outputs\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Note that generally speaking we'll mainly be using scalar (i.e. 0-dimensional\n",
        "# tensor) outputs that we call .backward() on. This is not too much of a\n",
        "# limitation because almost always a loss function will output a scalar. There\n",
        "# are ways to deal with non-scalar outputs, but it's irrelevant to us at the\n",
        "# moment and for now we'll just point out that trying to do so will cause an\n",
        "# error.\n",
        "try:\n",
        "    # example_output is not a scalar!\n",
        "    example_output.backward()\n",
        "except RuntimeError as e:\n",
        "    print(f\"Weren't able to calculate a gradient because of:\\n{str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "603cce0c",
      "metadata": {
        "id": "603cce0c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Notice now that we've turned example_output into a scalar, our call to\n",
        "# .backward() proceeds with no problem!\n",
        "example_scalar = example_output.sum()\n",
        "\n",
        "example_scalar.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "1a873e20",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a873e20",
        "outputId": "11dddf43-ce61-413b-e9ea-7c5925ee1da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_neural_net.layer_0=tensor([[ 2.6665e-02,  6.0188e-03, -3.6897e-02,  ..., -2.9631e-03,\n",
            "          2.7440e-03,  2.2885e-02],\n",
            "        [ 1.5650e-02,  1.0060e-02, -7.6510e-03,  ...,  4.4135e-02,\n",
            "         -1.0004e-02,  4.1362e-02],\n",
            "        [ 4.7334e-02, -4.9868e-02,  2.3435e-03,  ..., -4.4880e-02,\n",
            "         -7.6023e-03, -8.5151e-03],\n",
            "        ...,\n",
            "        [-4.7405e-02,  3.4039e-02,  3.1174e-02,  ...,  2.7006e-02,\n",
            "         -4.7982e-02, -4.7940e-02],\n",
            "        [ 3.4604e-02, -4.6491e-02, -2.1544e-02,  ..., -1.7410e-02,\n",
            "          2.9455e-02, -3.1414e-02],\n",
            "        [ 2.2848e-02,  3.0233e-02, -3.8859e-02,  ...,  4.8118e-02,\n",
            "          4.6384e-05,  4.1248e-02]], requires_grad=True)\n",
            "new_neural_net.layer_0.grad=tensor([[-3.8744e-02, -3.8744e-02, -3.8744e-02,  ..., -3.8744e-02,\n",
            "         -3.8744e-02, -3.8744e-02],\n",
            "        [ 1.8953e-01,  1.8953e-01,  1.8953e-01,  ...,  1.8953e-01,\n",
            "          1.8953e-01,  1.8953e-01],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-1.1841e-04, -1.1841e-04, -1.1841e-04,  ..., -1.1841e-04,\n",
            "         -1.1841e-04, -1.1841e-04],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        [-1.4663e-03, -1.4663e-03, -1.4663e-03,  ..., -1.4663e-03,\n",
            "         -1.4663e-03, -1.4663e-03]])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# And we can calculate the gradient of one of our neural net layers relative to\n",
        "# this scalar!\n",
        "\n",
        "print(f\"{new_neural_net.layer_0=}\")\n",
        "print(f\"{new_neural_net.layer_0.grad=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "f8b166a4",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "f8b166a4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# We'll need a few more pieces to actually be able to train our neural net.\n",
        "#\n",
        "# Remember how we mentioned that we need to make sure we reset gradients to\n",
        "# prevent gradient accumulation? Let's do that now.\n",
        "\n",
        "def zero_all_gradients(neural_net: ThreeLayerNeuralNet) -> None:\n",
        "    neural_net.layer_0.grad = None\n",
        "    neural_net.layer_0_bias.grad = None\n",
        "    neural_net.layer_1.grad = None\n",
        "    neural_net.layer_1_bias.grad = None\n",
        "    neural_net.layer_2.grad = None\n",
        "    neural_net.layer_2_bias.grad = None\n",
        "\n",
        "\n",
        "# Now let's implement the simplest loss function out there, the mean squared\n",
        "# error: https://en.wikipedia.org/wiki/Mean_squared_error. This consists of\n",
        "# squaring the difference between every component of the two tensors and taking\n",
        "# their mean.\n",
        "\n",
        "def loss_function(\n",
        "    expected_outputs: Float[t.Tensor, \"batch d_output\"],\n",
        "    actual_outputs: Float[t.Tensor, \"batch d_output\"],\n",
        ") -> Float[t.Tensor, \"\"]:\n",
        "    return t.mean((actual_outputs - expected_outputs)**2)\n",
        "\n",
        "\n",
        "# Now we can use derivatives/gradients to iteratively nudge an input tensor\n",
        "# towards a minimum with respect to a loss!\n",
        "\n",
        "def nudge_tensor_towards_minimum(x: t.Tensor, learning_rate: float) -> None:\n",
        "    # We need to do t.no_grad() here because we will be directly modifying x\n",
        "    # using x's gradients and we don't want to recompute x's gradients, since\n",
        "    # the only thing that should affect x's gradients is the loss function, not\n",
        "    # our adjustment to x.\n",
        "    with t.no_grad():\n",
        "        x = x + x.grad * (learning_rate*-1)\n",
        "\n",
        "# Finally we put all this together in a function that performs one iteration of\n",
        "# tuning the weights of neural nets in training.\n",
        "#\n",
        "# This function will do the following steps:\n",
        "#\n",
        "# 1. Zero all our gradients (using `zero_all_gradients``)\n",
        "# 2. Calculate the outputs our neural net produces (using `forward`)\n",
        "# 3. Compare those outputs against `expected_outputs` to calculate our loss\n",
        "#    using `loss_function`\n",
        "# 4. Adjust our neural net weights\n",
        "#\n",
        "# Reminder: remember to call `.backward()` on the appropriate function!\n",
        "#\n",
        "# This function is hard to write good test cases for, so before you proceed,\n",
        "# take a look at the solutions and make sure that your implementation is\n",
        "# equivalent (as well as the implementations of `forward`, `loss_function` and\n",
        "# `nudge_tensor_towards_minimum`!\n",
        "\n",
        "def tune_weights_once(\n",
        "    neural_net: ThreeLayerNeuralNet,\n",
        "    inputs: Float[t.Tensor, \"batch d_input\"],\n",
        "    expected_outputs: Float[t.Tensor, \"batch d_output\"],\n",
        "    learning_rate: float,\n",
        ") -> None:\n",
        "    zero_all_gradients(neural_net)\n",
        "    yhat = forward(inputs, neural_net)\n",
        "    loss = loss_function(expected_outputs, yhat)\n",
        "    loss.backward()\n",
        "    for t in (neural_net.layer_0, neural_net.layer_0_bias, neural_net.layer_1,\n",
        "              neural_net.layer_1_bias,neural_net.layer_2, neural_net.layer_2_bias,):\n",
        "      nudge_tensor_towards_minimum(t, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "19985ba0",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "19985ba0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Now we can actually train our neural net!\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(\n",
        "    neural_net: ThreeLayerNeuralNet,\n",
        "    inputs: t.Tensor,\n",
        "    expected_outputs: t.Tensor,\n",
        "    learning_rate: float,\n",
        "    number_of_iterations: int,\n",
        ") -> None:\n",
        "    print(f\"Initial loss was {loss_function(expected_outputs=expected_outputs, actual_outputs=forward(x=inputs, neural_net=neural_net))}\")\n",
        "    for _ in tqdm(range(number_of_iterations)):\n",
        "        tune_weights_once(neural_net, inputs, expected_outputs, learning_rate)\n",
        "    print(f\"Final loss was {loss_function(expected_outputs=expected_outputs, actual_outputs=forward(x=inputs, neural_net=neural_net))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "7c73556a",
      "metadata": {
        "id": "7c73556a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "329150da",
      "metadata": {
        "id": "329150da"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset = MNIST(root=\"data\", download=True, transform=ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "c56b906d",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "c56b906d",
        "outputId": "60e1e088-eab0-4aa9-bbd3-32f75b6cf24b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image is meant to express this numeral: 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79ae063d6530>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "img, label = dataset[0]\n",
        "\n",
        "print(f\"This image is meant to express this numeral: {label}\")\n",
        "plt.imshow(img.squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "54190b44",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "54190b44"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Before we can run training, there's one last thing we have to do: our images\n",
        "# come labeled with what digit they're supposed to represent, but that's a\n",
        "# single number, whereas our neural net outputs 10 components.\n",
        "#\n",
        "# That means we have to translate a number into a 10-component vector. E.g. if 2\n",
        "# is the correct answer, the ideal answer from our neural net would be [0, 0, 1,\n",
        "# 0, 0, 0, 0, 0, 0, 0].\n",
        "#\n",
        "# Doing this translation is called a \"one-hot encoding.\" Let's implement it!\n",
        "\n",
        "def one_hot_encoding(i: int, num_classes: int) -> t.Tensor:\n",
        "    zeros = t.zeros(num_classes, dtype=t.float)\n",
        "    zeros[i] = 1\n",
        "    return zeros\n",
        "\n",
        "assert_tensors_within_epsilon(\n",
        "    expected=t.tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
        "    actual=one_hot_encoding(2, 10),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "e44018df",
      "metadata": {
        "id": "e44018df"
      },
      "outputs": [],
      "source": [
        "\n",
        "# We also need to flatten an image down to a flat vector to make it suitable for\n",
        "# our neural net to ingest.\n",
        "\n",
        "def make_img_1d(imgs: t.Tensor) -> t.Tensor:\n",
        "    return einops.rearrange(imgs, '... h w -> ... (h w)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "1c3312dd",
      "metadata": {
        "id": "1c3312dd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This is an inefficient way of getting data from a dataset. We'll see later how\n",
        "# to do this more efficiently, but for now this suffices to demonstrate the\n",
        "# logic of how we're using our one-hot encoding and 1d flattening.\n",
        "\n",
        "training_imgs = []\n",
        "expected_outputs_in_training = []\n",
        "non_training_imgs = []\n",
        "expected_outputs_in_non_training = []\n",
        "counter = 0\n",
        "total_imgs = 2000\n",
        "num_of_training_imgs = 1000\n",
        "for img, label in dataset:\n",
        "    if counter >= total_imgs:\n",
        "        break\n",
        "    if counter < num_of_training_imgs:\n",
        "        training_imgs.append(make_img_1d(img).squeeze())\n",
        "        expected_outputs_in_training.append(one_hot_encoding(label, num_classes=10))\n",
        "    else:\n",
        "        non_training_imgs.append(make_img_1d(img).squeeze())\n",
        "        expected_outputs_in_non_training.append(one_hot_encoding(label, num_classes=10))\n",
        "    counter += 1\n",
        "\n",
        "training_imgs = t.stack(training_imgs)\n",
        "expected_outputs_in_training = t.stack(expected_outputs_in_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "a41ecbff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a41ecbff",
        "outputId": "82c223bc-780d-40d6-ba03-2eab0bf09586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training_imgs.shape=torch.Size([1000, 784])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"{training_imgs.shape=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "64359bff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "64359bff",
        "outputId": "299a6ff7-b19b-47aa-b318-a3393d69f2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected label: 0\n",
            "torch.Size([1, 2000])\n",
            "torch.Size([1, 400])\n",
            "torch.Size([1, 400])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 2000])\n",
            "torch.Size([1, 400])\n",
            "torch.Size([1, 400])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "Model guessed this was: 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Our neural net starts out with garbage predictions.\n",
        "\n",
        "non_training_img_idx = 0\n",
        "img_outside_of_training_dataset = non_training_imgs[non_training_img_idx]\n",
        "label = expected_outputs_in_non_training[non_training_img_idx].argmax()\n",
        "\n",
        "print(f\"Expected label: {label}\")\n",
        "plt.imshow(einops.rearrange(img_outside_of_training_dataset, '(h w) -> h w', h=28))\n",
        "\n",
        "model_all_guesses = forward(neural_net=new_neural_net, x=img_outside_of_training_dataset.unsqueeze(dim=0))\n",
        "model_guess_highest_prob = forward(neural_net=new_neural_net, x=img_outside_of_training_dataset.unsqueeze(dim=0)).argmax()\n",
        "\n",
        "print(f\"Model guessed this was: {model_guess_highest_prob}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "31ef0c43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31ef0c43",
        "outputId": "713350bb-843a-4ee0-8cfd-3beab0d82e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n",
            "Initial loss was 0.09339698404073715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/100 [00:00<00:39,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|         | 2/100 [00:00<00:38,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|         | 3/100 [00:01<00:37,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|         | 4/100 [00:01<00:39,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|         | 5/100 [00:02<00:39,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|         | 6/100 [00:02<00:38,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|         | 7/100 [00:02<00:36,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|         | 8/100 [00:03<00:40,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|         | 9/100 [00:03<00:37,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 10/100 [00:04<00:35,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|         | 11/100 [00:04<00:35,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|        | 12/100 [00:04<00:37,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|        | 13/100 [00:05<00:38,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|        | 14/100 [00:05<00:36,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|        | 15/100 [00:06<00:37,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|        | 16/100 [00:06<00:38,  2.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|        | 17/100 [00:07<00:39,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|        | 18/100 [00:08<00:45,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|        | 19/100 [00:08<00:52,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 20/100 [00:09<00:56,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|        | 21/100 [00:10<00:59,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|       | 22/100 [00:11<00:58,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|       | 23/100 [00:12<00:56,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|       | 24/100 [00:12<00:48,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|       | 25/100 [00:12<00:42,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|       | 26/100 [00:13<00:39,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|       | 27/100 [00:13<00:41,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|       | 28/100 [00:14<00:39,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|       | 29/100 [00:14<00:36,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 30/100 [00:15<00:33,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|       | 31/100 [00:15<00:33,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|      | 32/100 [00:16<00:31,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|      | 33/100 [00:16<00:30,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|      | 34/100 [00:17<00:33,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|      | 35/100 [00:17<00:33,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|      | 36/100 [00:18<00:31,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|      | 37/100 [00:18<00:31,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|      | 39/100 [00:19<00:25,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 40/100 [00:19<00:21,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|      | 41/100 [00:19<00:19,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|     | 42/100 [00:20<00:17,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|     | 43/100 [00:20<00:15,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|     | 44/100 [00:20<00:14,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|     | 45/100 [00:20<00:14,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|     | 46/100 [00:21<00:13,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|     | 47/100 [00:21<00:15,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|     | 48/100 [00:21<00:16,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|     | 49/100 [00:22<00:16,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 50/100 [00:22<00:16,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|     | 51/100 [00:22<00:16,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|    | 52/100 [00:23<00:16,  2.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|    | 53/100 [00:23<00:16,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|    | 55/100 [00:24<00:14,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|    | 56/100 [00:24<00:13,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|    | 57/100 [00:24<00:11,  3.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|    | 58/100 [00:24<00:10,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|    | 59/100 [00:25<00:10,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 60/100 [00:25<00:10,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|    | 61/100 [00:25<00:09,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|   | 62/100 [00:25<00:09,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|   | 63/100 [00:26<00:08,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|   | 64/100 [00:26<00:08,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|   | 65/100 [00:26<00:08,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|   | 66/100 [00:26<00:07,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|   | 67/100 [00:27<00:07,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|   | 68/100 [00:27<00:07,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|   | 69/100 [00:27<00:07,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 70/100 [00:27<00:06,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|   | 71/100 [00:27<00:06,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|  | 72/100 [00:28<00:06,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|  | 73/100 [00:28<00:06,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|  | 74/100 [00:28<00:05,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|  | 75/100 [00:28<00:05,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|  | 76/100 [00:29<00:05,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|  | 77/100 [00:29<00:05,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|  | 78/100 [00:29<00:05,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|  | 79/100 [00:29<00:04,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 80/100 [00:30<00:04,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|  | 81/100 [00:30<00:04,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%| | 82/100 [00:30<00:04,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%| | 83/100 [00:30<00:03,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%| | 84/100 [00:30<00:03,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%| | 85/100 [00:31<00:03,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%| | 86/100 [00:31<00:03,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%| | 87/100 [00:31<00:03,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%| | 88/100 [00:31<00:02,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%| | 89/100 [00:32<00:02,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 90/100 [00:32<00:02,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%| | 91/100 [00:32<00:02,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|| 92/100 [00:32<00:01,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|| 93/100 [00:33<00:01,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|| 94/100 [00:33<00:01,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|| 95/100 [00:33<00:01,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|| 96/100 [00:33<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|| 97/100 [00:33<00:00,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|| 98/100 [00:34<00:00,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|| 99/100 [00:34<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 100/100 [00:35<00:00,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2000])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 400])\n",
            "torch.Size([1000, 10])\n",
            "torch.Size([1000, 10])\n",
            "Final loss was 0.09339698404073715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Now let's train our neural net!\n",
        "train(\n",
        "    neural_net=new_neural_net,\n",
        "    inputs=training_imgs,\n",
        "    expected_outputs=expected_outputs_in_training,\n",
        "    # A learning rate of 2 is usually much too high, but we've made some sub-optimal choices in designing our\n",
        "    learning_rate=10,\n",
        "    number_of_iterations=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "2d14b996",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "2d14b996",
        "outputId": "751b3d22-1fa8-4ffe-eb1d-0b26715dfb37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected label: 0\n",
            "torch.Size([1, 2000])\n",
            "torch.Size([1, 400])\n",
            "torch.Size([1, 400])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 2000])\n",
            "torch.Size([1, 400])\n",
            "torch.Size([1, 400])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "Model guessed this was: 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# And let's try again\n",
        "\n",
        "print(f\"Expected label: {label}\")\n",
        "plt.imshow(einops.rearrange(img_outside_of_training_dataset, '(h w) -> h w', h=28))\n",
        "\n",
        "model_all_guesses = forward(neural_net=new_neural_net, x=img_outside_of_training_dataset.unsqueeze(dim=0))\n",
        "model_guess_highest_prob = forward(neural_net=new_neural_net, x=img_outside_of_training_dataset.unsqueeze(dim=0)).argmax()\n",
        "\n",
        "print(f\"Model guessed this was: {model_guess_highest_prob}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "06f25a49",
      "metadata": {
        "id": "06f25a49"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Here's a demonstration of how we could write this using PyTorch entirely. In\n",
        "# two days you will have implemented every PyTorch function and class here from\n",
        "# scratch!\n",
        "\n",
        "class SimpleNeuralNet(t.nn.Module):\n",
        "    def __init__(self, *args, **kwargs) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.implementation = t.nn.Sequential(\n",
        "            t.nn.Linear(in_features=784, out_features=2000),\n",
        "            t.nn.ReLU(),\n",
        "            t.nn.Linear(in_features=2000, out_features=400),\n",
        "            t.nn.ReLU(),\n",
        "            t.nn.Linear(in_features=400, out_features=10),\n",
        "            t.nn.Softmax(dim=-1),\n",
        "        )\n",
        "\n",
        "    def forward(self, t: t.Tensor):\n",
        "        return self.implementation(t)\n",
        "\n",
        "\n",
        "def train(model: SimpleNeuralNet, epochs: int, lr: int):\n",
        "    optimizer = t.optim.SGD(model.parameters(), lr=lr)\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        output = model(training_imgs)\n",
        "        # For those who are confused why we use MSE loss here for a\n",
        "        # classification task, see https://arxiv.org/abs/2006.07322\n",
        "        loss = t.nn.functional.mse_loss(output, expected_outputs_in_training)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch == 0:\n",
        "            print(f\"Initial loss: {loss=}\")\n",
        "        elif epoch == epochs - 1:\n",
        "            print(f\"Final loss: {loss=}\")\n",
        "\n",
        "model = SimpleNeuralNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "fb59b35a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb59b35a",
        "outputId": "ef4f6815-69d7-4c0c-eff2-cc88be508d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [00:00<00:30,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss: loss=tensor(0.0900, grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 100/100 [00:20<00:00,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final loss: loss=tensor(0.0046, grad_fn=<MseLossBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train(model, epochs=100, lr=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "3a5b8cdb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "3a5b8cdb",
        "outputId": "79fba8c0-591d-4a3c-a995-2b3ee13fad69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected label: 0\n",
            "Model guessed this was: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Let's look at an image that wasn't part of the training data\n",
        "\n",
        "non_training_img_idx = 0\n",
        "img_outside_of_training_dataset = non_training_imgs[non_training_img_idx]\n",
        "label = expected_outputs_in_non_training[non_training_img_idx].argmax()\n",
        "\n",
        "print(f\"Expected label: {label}\")\n",
        "plt.imshow(einops.rearrange(img_outside_of_training_dataset, '(h w) -> h w', h=28))\n",
        "\n",
        "model_all_guesses = model(img_outside_of_training_dataset)\n",
        "model_guess_highest_prob = model(img_outside_of_training_dataset).argmax()\n",
        "\n",
        "print(f\"Model guessed this was: {model_guess_highest_prob}\")"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}